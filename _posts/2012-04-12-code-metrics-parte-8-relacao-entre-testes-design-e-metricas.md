---
id: 15
title: 'Code metrics (parte 8) &#8211; RelaÃ§Ã£o entre testes, design e mÃ©tricas'
date: '2012-04-12T13:36:00-03:00'
author: 'Leandro Daniel'

guid: /post/Code-metrics-(parte-8)-RelacaoMetricasTestesDesign.aspx
permalink: /index.php/code-metrics-parte-8-relacao-entre-testes-design-e-metricas/
categories:
    - Arquitetura
    - Post
---

Continuando a sÃ©rie de posts sobre [Code Metrics](http://leandrodaniel.com/?tag=/Code+Metrics), essa semana gostaria de trazer o resultado de uma discussÃ£o promovida via [Gist](https://gist.github.com/).

Em suma, eu queria discutir com alguns amigos sobre a relaÃ§Ã£o existente entre testes, design e mÃ©tricas. Para promover o debate, elaborei um cenÃ¡rio para servir como background, baseado em um [post](http://whileicompile.wordpress.com/2010/09/14/what-is-too-simple-and-small-to-refactor-as-clean-code) que li onde o autor aplicava, na visÃ£o dele, as recomendaÃ§Ãµes do Uncle Bob descritas no livro [Clean Code](http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882).

Como ferramenta para a nossa discussÃ£o, criei um Gist, assim todos poderiam comentar, escrever outros cÃ³digos ou atÃ© mesmo forkar, se desejassem. Participaram da discussÃ£o (por ordem de chegada): [@giggio](https://github.com/giggio), [@vquaiato](https://github.com/vquaiato), [@juanplopes](https://github.com/juanplopes), [@mauricioaniche](https://github.com/mauricioaniche), [@felipero](https://github.com/felipero), [@ElemarJR](https://github.com/ElemarJR), [@tucaz](@marcioalthmann) e [@marcioalthmann.](https://github.com/marcioalthmann)

Fiquei muito feliz e honrado com o quÃ³rum reunido. Foi uma discussÃ£o muito boa, de alto nÃ­vel (como era de se esperar dos participantes).   
![Smile](http://leandrodaniel.com/editors/tiny_mce_3_4_3_1/plugins/emotions/img/smiley-smile.gif "Smile")

### Vamos ao cenÃ¡rio

No exemplo que propus, um desenvolvedor codificou em C# uma classe que realizava cÃ¡lculo de salÃ¡rios ([veja a classe aqui](https://gist.github.com/2149474?file=exemplo_depois.cs#file_exemplo_antes.cs)). Aplicando refactoring nessa classe, ele acabou por quebrÃ¡-la em 3, extraiu e separou alguns mÃ©todos e deu outra abordagem para resolver o mesmo problema ([veja o resultado aqui](https://gist.github.com/2149474?file=exemplo_depois.cs#file_exemplo_depois.cs)).

Algumas mÃ©tricas foram coletadas antes e depois do refactoring. Veja os resultados abaixo.

![](http://leandrodaniel.com/pics/metricasResult.png)

ApÃ³s apresentar esse cenÃ¡rio, fiz uma sÃ©rie de questionamentos e convidei, via Twitter, alguns amigos para colaborarem com suas percepÃ§Ãµes. Os tÃ³picos a seguir descrevem as questÃµes com as participaÃ§Ãµes da galera. Perceba a riqueza das participaÃ§Ãµes.

### QuestÃ£o 1 â€“ Qual a relaÃ§Ã£o entre Testes x CC?

De modo geral, podemos ter como prÃ¡tica que o set de testes deve, no mÃ­nimo, ter o mesmo nÃºmero de testes que o resultado do indicador CC (cyclomatic complexity)? Por exemplo, se um mÃ©todo tem 5 de CC, ele deve ter no mÃ­nimo 5 testes escritos para ele.

A saber:

- estou considerando apenas um assert por mÃ©todo de test;
- nÃ£o considerando a eficÃ¡cia do teste escrito.

Confira as respostas:

> [@vquaiato](https://github.com/vquaiato)   
> 5 testes talvez seja o mÃ­nimo pelos cenÃ¡rios de saÃ­da do mÃ©todo, mas existem outras combinaÃ§Ãµes e outras formas de testar.
> 
> [@juanplopes](https://github.com/juanplopes)   
> Sim, no mÃ­nimo. Entretanto existem outros pontos que aumentam a complexidade ciclomÃ¡tica sem ela aparecer nas mÃ©tricas. Um Math.Max, Ã© um exemplo.
> 
> [@mauricioaniche](https://github.com/mauricioaniche)   
> Sim, concordo que CC = N, entÃ£o N Ã© o nÃºmero mÃ­nimo de testes que vc deve ter. SÃ³ nÃ£o testaria mÃ©todos com CC=1 e cujo cÃ³digo apenas repassa a invocaÃ§Ã£o de mÃ©todo pra alguma outra classe, ou cujo mÃ©todo seja um getter/setter. Nesses casos, nÃ£o testaria.
> 
> [@felipero](https://github.com/felipero)   
> Se tem 5 CC, devem ter mais testes (considerando 1 assert por teste) porque precisa testar o comportamente no sucesso e na falha, entÃ£o seriam no mÃ­nimo 10 testes. Eu uso o acrÃ´nimo do Right B I C E P S para validar os casos de teste que escrevo. Veja [aqui](http://media.pragprog.com/titles/utj/StandaloneSummary.pdf) e [aqui](http://testen.fontysvenlo.org/metiq/wk03/wk03_handout.pdf).
> 
> [@giggio](https://github.com/giggio)   
> Vou na do Aniche, mas acrescento que nÃ£o testaria nada muito Ã³bvio. Tentar buscar 100% de cobertura nÃ£o faz sentido.
> 
> [@marcioalthmann](https://github.com/marcioalthmann)   
> Sim, no mÃ­nimo, quando preciso testar cÃ³digos assim geralmente verifico a cobertura de cÃ³digo para garantir que passei por todo lugar.

### QuestÃ£o 2 â€“ Qual a relaÃ§Ã£o entre Cobertura de testes x MÃ©tricas?

Membros privados podem ser ignorados nos testes? Devemos garantir os testes pelos membros pÃºblicos observando a cobertura de cÃ³digo dos testes. Isso Ã© suficiente? (sem entrar no mÃ©rito da necessidade ou nÃ£o de 100% de cobertura. A intenÃ§Ã£o aqui Ã© deduzir uma relaÃ§Ã£o entre mÃ©tricas â€“ total de membros privados/pÃºblicos, por exemplo â€“ e testes.

Respostas:

> [@vquaiato](https://github.com/vquaiato)   
> sobre os testes de mÃ©todos privados, como jÃ¡ discuti muito no DNA, existem cenÃ¡rios onde sÃ£o aplicÃ¡veis, principalmente se sua interface pÃºblica Ã© muito simples e seus mÃ©todos privados englobam algoritmos mais complexos. Honestamente hoje nÃ£o me preocupo com isso se minha API nÃ£o Ã© pÃºblica e Ã© apenas de consumo dentro do prÃ³prio projeto.
> 
> [@juanplopes](https://github.com/juanplopes)   
> Membros privados, numa classe coesa devem ser sempre utilizados pelo conjunto de testes. Isto Ã©, se um mÃ©todo pÃºblico nÃ£o utiliza um membro privado, hÃ¡ um problema de coesÃ£o ai, nÃ£o? E se o membro privado faz operaÃ§Ãµes suficientes para precisar ser testado, provavelmente vocÃª precise isolÃ¡-lo.
> 
> [@mauricioaniche](https://github.com/mauricioaniche)   
> Sim. Em uma classe coesa, os mÃ©todos privados no fundo servem pra diminuir a CC e aumentar a legibilidade dos mÃ©todos pÃºblicos. Eu nÃ£o quero testar COMO uma classe faz, mas sim O QUE ela faz. NÃ£o vejo pq entÃ£o testar um mÃ©todo privado diretamente.
> 
> [@felipero](https://github.com/felipero)   
> Precisa usar o bom senso. NÃ£o gosto de mudar a estrutura de encapsulamento somente para poder testar algo. Mas isso provavelmente serÃ¡ necessÃ¡rio para casos de testes complexos. Nesse caso hÃ¡ alguns frameworks que "burlam" essa proteÃ§Ã£o quando em teste, mas acho isso perigoso. Eu me conformo com isso e testo via mÃ©todos pÃºblicos mesmo, apesar de nÃ£o gostar. Pode usar a cobertura de testes para aferir se tudo estÃ¡ testado. Mas nÃ£o deve haver cobranÃ§a e nem usar isso como lei.
> 
> [@giggio](https://github.com/giggio)   
> Essa discussÃ£o Ã© velha. Depende. MÃ©todos privados sÃ£o detalhes de implementaÃ§Ã£o, e podem mudar. Isso nÃ£o significa que eu, que implementei, nÃ£o quero saber se funcionam. EntÃ£o eu diria que vocÃª tem que testar no mÃ­nimo o mÃ©todo publico que chama o privado, e se a complexidade do privado demandar um teste, faÃ§a, oras. Esse negÃ³cio de extrair uma classe pra poder testar o mÃ©todo privado Ã© bonito e tudo, mas nem sempre isso faz sentido.
> 
> [@marcioalthmann](https://github.com/marcioalthmann)   
> Essa depende mesmo, testo mÃ©todos privados mas ai tenho que concordar com o @juanplopes talvez tenha um probleminha em precisar testar esses caras ğŸ™‚

### QuestÃ£o 3 â€“ Qual a relaÃ§Ã£o entre MÃ©tricas x Design?

Quando, atravÃ©s de mÃ©tricas, chegamos a conclusÃ£o que o cÃ³digo ficou mais complexo, Ã© uma boa estratÃ©gia considerar LoC (lines of code) como indicador para comparar "antes" e "depois"? Que outras mÃ©tricas vocÃªs considerariam?

Respostas:

> [@vquaiato](https://github.com/vquaiato)   
> e a complexidade extra adicionada para decidir quais classes filhas serÃ£o usadas? Qual mÃ©trica te revela isso? Pois a resoluÃ§Ã£o de qual classe filha usar vai ter que estar em algum lugar: um componente extra, um SL, uma decisÃ£o a mais em alguma camada, etc, etc. sobre o cÃ³digo mais complexo, atravÃ©s das mÃ©tricas, Ã© complicado dizer. depende bastante do feeling de quem estÃ¡ lendo/escrevendo. Para alguns o cÃ³digo refatorado Ã© melhor, mais extensÃ­vel, manutenÃ­vel, testÃ¡vel, etc, etc, etc. Mas ler o primeiro cÃ³digo Ã© way better que o segundo. Depende entÃ£o do que as mÃ©tricas significam para quem trabalha nesse projeto.
> 
> [@juanplopes](https://github.com/juanplopes)   
> NÃ£o utilizo mÃ©tricas somente para verificar se um cÃ³digo ficou ou nÃ£o mais complexo. As mÃ©tricas ajudam, mas isso Ã© um fator muito subjetivo. O LOC Ã© um dos fatores que mais enganam nesse sentido, que geralmente levam a um cÃ³digo menor, porÃ©m geralmente mais complexo.
> 
> [@mauricioaniche](https://github.com/mauricioaniche)   
> Vc tem que considerar LOC, Fan Out, CC, LCOM, Instability, # de mÃ©todos, # de atributos, e assim por diante. NÃ£o Ã© fÃ¡cil; cada uma das mÃ©tricas atua em um nÃ­vel diferente. Gosto muito da ideia do Erik Doenerburg (nÃ£o sei escrever bem). Ele tem o Toxicity Chart, onde ele tem juntar todas as mÃ©tricas em um grÃ¡fico sÃ³, e achar em uma mÃ©trica maior. Nos meus estudos de mineraÃ§Ã£o de repositÃ³rio de dados, uma coisa que me agrada Ã© fazer estatÃ­sticas descritivas simples, e ver quem fica fora da mÃ©dia/mediana + desvio padrÃ£o, por exemplo. Acho essa uma boa maneira de analisar uma mÃ©trica.
> 
> [@felipero](https://github.com/felipero)   
> LoC nÃ£o Ã© diretamente proporcional Ã  complexidade. Se considerarmos complexidade de entendimento e leitura do cÃ³digo, que afeta diretamente a manutenÃ§Ã£o, TCO e produtividade dos desenvolvedores, podemos concluir que isso:
> 
> return algo ? outra\_coisa : null
> 
> Ã© mais complexo para se entender do que isso:
> 
> if(algo == true) {   
>  return outra\_coisa   
> } else {   
>  return null   
> }
> 
> [@ElemarJR](https://github.com/ElemarJR)   
> O problema, como eu vejo Ã© que as classes foram criadas para atender apenas um comportamento. Ao meu ver, esse "desvio" dos indicadores ficarÃ¡ diluÃ­do na medida em que esses objetos "ganharem corpo".. o que deverÃ¡ ocorrer naturalmente.
> 
> [@giggio](https://github.com/giggio)   
> Sendo bem sincero, eu acho que nenhuma mÃ©trica resolveria. Trabalhar orientado a um nÃºmero nÃ£o garante sucesso. Estamos medindo produtos intermediÃ¡rios? Porque?
> 
> [@marcioalthmann](https://github.com/marcioalthmann)   
> Cara nÃ£o sei, acho que LoC nÃ£o vai ajudar a dizer que ficou mais complexo, muita linha de cÃ³digo simples Ã© melhor que pouca linha de cÃ³digo complexo :D. E ai depende do "feeling" que o @vquaiato disse. Agora pensandoâ€¦ e se alÃ©m de LoC considerar nÃºmero de testes? Acho que nesse exemplo o nÃºmero de testes para o cÃ³digo refatorado acabaria maior do que com o cÃ³digo sem refatorar.

### QuestÃ£o 4 â€“ Qual a melhor "unidade" para os testes unitÃ¡rios?

Qual a melhor "unidade" para orientarmos a escrita de testes (de unidade, claro): mÃ©todo, classe, assembly, assunto de negÃ³cio ou outra? (estou falando aqui de "Testes de Unidade": qual unidade vocÃª comumente utiliza?)

Respostas:

> [@vquaiato](https://github.com/vquaiato)   
> Mesmo testando "unidade" hoje eu costumo utilizar unidades de negÃ³cio e nÃ£o de "engenharia". Claro que acabam existindo ambos no projeto, mas tenho procurado seguir na linha de negÃ³cio.
> 
> [@juanplopes](https://github.com/juanplopes)   
> Classe. Se vocÃª tem mÃ©todos distintos na classe que precisam ser testados isoladamente, provavelmente eles deveriam ser outra classe para manter a responsabilidade Ãºnica.
> 
> [@mauricioaniche](https://github.com/mauricioaniche)   
> IMHO, a unidade em um sistema OO Ã© uma classe. SÃ£o classes que vc passa de um lado para o outro. CancelUpdate Comment.
> 
> [@felipero](https://github.com/felipero)   
> NÃ£o gosto da ideia de testes de unidade focarem em negÃ³cio. Acho que precisam testar o comportamento tÃ©cnico de uma unidade de cÃ³digo. Eu utilizo "objetos" (classes, traits, structures, enums) como unidade. Testo cada um de seus mÃ©todos pÃºblicos. EntÃ£o, tenho uma classe de teste unitÃ¡rio para cada classe da app (com exceÃ§Ã£o de controllers em aplicaÃ§Ãµes MVC). Isso me dÃ¡ satisfaÃ§Ã£o suficiente em casos mais triviais.
> 
> Acho porÃ©m fundamental que esses testes de unidade que faÃ§o sejam menos prioritÃ¡rios em relaÃ§Ã£o a testes que verifiquem as "operaÃ§Ãµes de negÃ³cio". SÃ£o testes que asseguram o comportamento de uma ou mais classes, de forma nÃ£o isolada, para que eu saiba quando uma determinada operaÃ§Ã£o, aÃ§Ã£o ou funcionalidade do sistema estÃ¡ funcionando. Eu faÃ§o isso independente da interface de usuÃ¡rio normalmente. (Ã‰ aqui que testo os controllers, de forma integrada). Em paralelo, utilizo testes de selenium para verificar se a interface de usuÃ¡rio estÃ¡ se comportando de acordo. Mas para interfaces, eu gosto muito de testes manuais.
> 
> [@giggio](https://github.com/giggio)   
> Eu tenho uma regra pessoal: considero que um teste Ã© de unidade se ele nÃ£o acessa nada de infraestrutura, e se nÃ£o cruza fronteiras lÃ³gicas de componentes, o que em .NET significa o Assembly. Eu nÃ£o isolo classes de domÃ­nio umas das outras. E considero isolar classes e mÃ©todos em linguagens estÃ¡ticas insano, porque dÃ¡ muito trabalho.
> 
> [@marcioalthmann](https://github.com/marcioalthmann)   
> Classe

### Se vocÃª quiser ver o Gist completoâ€¦

Basta acessÃ¡-lo [aqui e ler todos os comentÃ¡rios](https://gist.github.com/2149474). Fique Ã  vontade para comentar tambÃ©m. ğŸ˜‰

### ConclusÃ£o?

Nos prÃ³ximos posts da sÃ©rie abordarei vÃ¡rios pontos oriundos do debate acima. ğŸ˜‰